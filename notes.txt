
- first task is to separate all pages into their own separate pdf files

- first, i tried using title extraction with openAI vision to extract titles from each pdf
    - the goal here was to use patching and openai vision on these patch sub sections of the pdf to collect all distinct items in the pdf
    - i was worried of the efficact at first, so i decided to move on for now

- found a repo with john that claims to have a solution for P&ID document feature extraction
    - i spent many hours trying to set up the enviornment, the docker container, and the azure resouces
    - eventually, i realized that the rpo does not even contain a usable model, only the wrapping infra to use a P&ID trained vision model that must be self-hosted
    - basically was a waste of time

- back to openai vision patching, but doing some research on better ways to collect information within each patch of a document before vision is used
    - first i tried extracting all text items from each pdf
        - this failed, as most of the documents didnt really contain explicitly defined text objects
        - however, it doesnt really hurt to include
    - what do we need to fetch from each document:
        - primary identifiers: equipment tags, instrument tags, line numbners, etc.
        - titles
        - keywords: compact, what is this page about
    - Use OCR to fetch all important items from document
        - PaddleOCR: this model also outputs confidence scores, so we can filter by confidence for valid items