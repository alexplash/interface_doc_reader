
- first task is to separate all pages into their own separate pdf files

- first, i tried using title extraction with openAI vision to extract titles from each pdf
    - the goal here was to use patching and openai vision on these patch sub sections of the pdf to collect all distinct items in the pdf
    - i was worried of the efficacy at first, so i decided to move on for now

- found a repo with john that claims to have a solution for P&ID document feature extraction
    - i spent many hours trying to set up the enviornment, the docker container, and the azure resouces
    - eventually, i realized that the repo does not even contain a usable model, only the wrapping infra to use a P&ID trained vision model that must be self-hosted
    - basically was a waste of time

- back to openai vision patching, but doing some research on better ways to collect information within each patch of a document before vision is used
    - first i tried extracting all text items from each pdf
        - this failed, as most of the documents didnt really contain explicitly defined text objects
        - however, it doesnt really hurt to include
    - what do we need to fetch from each document:
        - primary identifiers: equipment tags, instrument tags, line numbners, etc.
        - titles
        - keywords: compact, what is this page about
    - Use OCR to fetch all important items from document
        - PaddleOCR: this model also outputs confidence scores, so we can filter by confidence for valid items

- now it is time to implement the document ranking system, based on a user input
    - first i set up a standard agentic conversation loop, with GPT 5 as the conversation tool
        - user inputs query, and agent determines query terms and triggers document ranker to fetch relevant documents
    - document ranker initially used simple search term presense in items from metadata file
        - this failed to work, as direct string matching is not very practical for the format of data that exists for the ocr items
        - broken tokens, spacing issues, partial identifiers, etc.
    - then i tried using a full gpt pass over query terms and document meta data as the document ranking system
        - gpt was able to very accurately determine relevant documents, but cost and time is an issue
    - to fix cost and time issues with pure gpt ranker, i added an initial string matching and embedding similarity scan to determine candidate docs to send to gpt
        - for id-like query terms ("HE-750-140"), i used string-string matching to find documents that contain identical or similar id-like objects
        - for name/title query terms ("NGL PREHEAT EXCHANGER"), i used embeddings and cosine similarity scoring to find documents that contain similar items
        - these "candidate" documents are then sent through the previously created gpt ranker
        - the process is now much faster, cheaper, and possibly even more precise


- future improvements:
    - Replace PaddleOCR with a P&ID-specific vision extractor
        - this will improve the information in metadata.json significantly, allowing for much more accurate scanning in the document ranker
        - this is especially apparent in the initial embedding and id-match scan, because the current metadata items can lead to potentially relevant documents being ommitted from the candidate pool of documents
    - add post-ranking agentic tools
        - as of now, the agent only returns relevant documents
        - the user should be able to ask questions regarding these documents
        - using vision model to interpret relevant documents and return answer back to user
    - handle negation and "not" queries
        - if the user asks something like "where is {x} not being used", the agent will return back the documents where x is a relevant item
        - so there should be a query intent classifier that is determined by the rank_documents tool call, as well as the query item selection
            - this query intent tool with then allow us to tune the way the document ranker selects documents, rather than just naively fetching matches
    